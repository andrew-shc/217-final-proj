{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e3459c",
   "metadata": {},
   "source": [
    "# Automatic Map Initialization\n",
    "The main goal of this is to compute the relative pose between 2 frames to triangulate an initial set of map pts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972fa8b",
   "metadata": {},
   "source": [
    "## 1. Find initial correspondences\n",
    "There's several steps they use to determine if two frames are suitible to generate the intial map points. \n",
    "\n",
    "Their first main \"test\" is a method where they use where they extract only the fine ORB features, and then search for matches between their current frame $F_c$ and reference frame $F_r$. If there aren't enough matches, we reset the reference frame. \n",
    "\n",
    "In terms of their code, they do a clever method of tracking only a window of ORB features and testing from that. \n",
    "\n",
    "Again, note that this is part of a set of tests to determine if two frames are suitible to generate an intial set of map points. If at any point it fails, it will reject it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af44ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "PATH_TO_IMG1 = \"./parallax_1.jpg\"\n",
    "PATH_TO_IMG2 = \"./parallax_2.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORBCorrespondence:\n",
    "    def __init__(\n",
    "            self,\n",
    "            nn_ratio: float = 0.6, \n",
    "            check_orientation: bool = True,\n",
    "            window_size: int = 10, \n",
    "            min_matches: int = 100\n",
    "            ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes ORB correspondances for SLAM map initialization.\n",
    "\n",
    "        :param nn_ratio: Nearest neighbor for Lowe's ratio test.\n",
    "        :param check_orientation: Check for orientation consistency (generally good).\n",
    "        :param window_size: Search window in pixels (px).\n",
    "        :param min_matches: Minimum ORB matches required. \n",
    "        \"\"\"\n",
    "        self.nn_ratio = nn_ratio\n",
    "        self.check_orientation = check_orientation\n",
    "        self.window_size = window_size\n",
    "        self.min_matches = min_matches\n",
    "\n",
    "        # as mentioned in the paper, just use orb at the finest scale\n",
    "        self.orb = cv2.ORB.create(\n",
    "            nfeatures=1000,\n",
    "            scaleFactor=1.2,\n",
    "            nlevels=1, # finest level param\n",
    "            edgeThreshold=31,\n",
    "            firstLevel=0,\n",
    "            WTA_K=2,\n",
    "            scoreType=cv2.ORB_HARRIS_SCORE,\n",
    "            patchSize=31,\n",
    "            fastThreshold=20\n",
    "        )\n",
    "    \n",
    "    def extract_orb_features(\n",
    "            self, \n",
    "            img: np.ndarray\n",
    "            ) -> tuple[list[cv2.KeyPoint], np.ndarray]:\n",
    "        \"\"\"\n",
    "        Does what you think it does. \n",
    "        (extract ORB features lol)\n",
    "        \n",
    "        :param img: Input grayscale img.\n",
    "\n",
    "        :return keypoints: List of detected keypoints. \n",
    "        :return descriptors: Feature descriptors (BRIEF) (n x 32 uint8 array).\n",
    "        \"\"\"\n",
    "\n",
    "        kp, des = self.orb.detectAndCompute(img, None)\n",
    "\n",
    "        if des is None:\n",
    "            return [], np.array([])\n",
    "        \n",
    "        return kp, des\n",
    "    \n",
    "    def hamming_distance(\n",
    "            self, \n",
    "            desc1: np.ndarray, \n",
    "            desc2: np.ndarray\n",
    "        ) -> int:\n",
    "        \"\"\"\n",
    "        Computes the Hamming distance between 2 ORB descriptors. \n",
    "\n",
    "        :param desc1: ORB descriptor 1\n",
    "        :param desc2: ORB descriptor 2\n",
    "\n",
    "        :return: Hamming distance (0 - 256)\n",
    "        \"\"\"\n",
    "        return np.sum(np.unpackbits(desc1 ^ desc2))\n",
    "    \n",
    "    def search_for_initialization(\n",
    "            self,\n",
    "            frame_ref: np.ndarray,\n",
    "            frame_curr: np.ndarray,\n",
    "            prev_matched: Optional[list[tuple[float, float]]] = None\n",
    "        ) -> tuple[list[int], list[tuple[float, float]], int]:\n",
    "        \"\"\"\n",
    "        Finds correspondances between reference and current frame.\n",
    "\n",
    "        :param frame_ref: Reference frame\n",
    "        :param frame_curr: Current frame\n",
    "        :param prev_matched: Previous matched points for guided search\n",
    "\n",
    "        :return matches_12: Match indices (ref_idx -> curr_idx, -1 if none)\n",
    "        :return matched_points: Updated matched point positions\n",
    "        :return num_matches: Number of successful matches\n",
    "        \"\"\"\n",
    "        # get ORB feat\n",
    "        kp_ref, desc_ref   = self.extract_orb_features(frame_ref)\n",
    "        kp_curr, desc_curr = self.extract_orb_features(frame_curr)\n",
    "\n",
    "        if len(kp_ref) == 0 or len(kp_curr) == 0:\n",
    "            return [], [], 0\n",
    "        \n",
    "        # init outputs\n",
    "        matches_12 = [-1] * len(kp_ref)\n",
    "        matched_pts = []\n",
    "\n",
    "        # now match keypts to each other within a window\n",
    "        pts_ref = np.array([kp.pt for kp in kp_ref])\n",
    "        pts_curr = np.array([kp.pt for kp in kp_curr])\n",
    "\n",
    "        for i, (kp_r, desc_r) in enumerate(zip(kp_ref, desc_ref)):\n",
    "            # search window\n",
    "            if prev_matched and i < len(prev_matched):\n",
    "                # use previous match if exists\n",
    "                center_x, center_y = prev_matched[i].x, prev_matched[i].y\n",
    "            else:\n",
    "                # use current kp as center of window\n",
    "                center_x, center_y = kp_r.pt\n",
    "            \n",
    "            # find potetial matches in window\n",
    "            candidates = []\n",
    "            for j, (kp_c, desc_c) in enumerate(zip(kp_curr, desc_curr)):\n",
    "                dx = kp_c.pt[0] - center_x\n",
    "                dy = kp_c.pt[1] - center_y\n",
    "\n",
    "                # within window\n",
    "                if abs(dx) <= self.window_size and abs(dy) <= self.window_size:\n",
    "                    dist = self.hamming_distance(desc_r, desc_c)\n",
    "                    candidates.append((j, dist))\n",
    "            \n",
    "            if len(candidates) < 2: # not enough\n",
    "                continue\n",
    "\n",
    "            candidates.sort(key=lambda x: x[1]) # sort by dist\n",
    "            \n",
    "            # Lowe's ratio test \n",
    "            best_dist_1 = candidates[0][1]\n",
    "            best_dist_2 = candidates[1][1]\n",
    "\n",
    "            if best_dist_1 < self.nn_ratio * best_dist_2:\n",
    "                best_idx = candidates[0][0]\n",
    "\n",
    "                # orientation consistency\n",
    "                if self.check_orientation:\n",
    "                    angle_diff = abs(kp_ref[i].angle - kp_curr[best_idx].angle)\n",
    "                    angle_diff = min(angle_diff, 360 - angle_diff) # wraparound\n",
    "\n",
    "                    if angle_diff > 30: # if more than 30 break\n",
    "                        continue\n",
    "                \n",
    "                # store match\n",
    "                matches_12[i] = best_idx\n",
    "                matched_pts.append((kp_curr[best_idx].pt[0], kp_curr[best_idx].pt[1]))\n",
    "        \n",
    "        # successful matches seen\n",
    "        num_matches = sum(1 for match in matches_12 if match != -1)\n",
    "\n",
    "        return matches_12, matched_pts, num_matches\n",
    "    \n",
    "    def get_matched_keypoints(\n",
    "            self, \n",
    "            kp_ref: list[cv2.KeyPoint],\n",
    "            kp_curr: list[cv2.KeyPoint],\n",
    "            matches_12: list[int]\n",
    "        ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Extract the matched kp coordinates (np.ndarray)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        pts_ref = []\n",
    "        pts_curr = []\n",
    "\n",
    "        for i, match_idx in enumerate(matches_12):\n",
    "            if match_idx != -1:\n",
    "                pts_ref.append(kp_ref[i].pt)\n",
    "                pts_curr.append(kp_curr[match_idx].pt)\n",
    "        \n",
    "        return np.array(pts_ref), np.array(pts_curr)\n",
    "\n",
    "    def visualize_matches(\n",
    "            self,\n",
    "            img_ref, img_curr,\n",
    "            kp_ref, kp_curr,\n",
    "            matches_12\n",
    "        ) -> np.ndarray:\n",
    "        good_matches = []\n",
    "        for i, match_idx in enumerate(matches_12):\n",
    "            if match_idx != -1:\n",
    "                good_matches.append(cv2.DMatch(i, match_idx, 0))\n",
    "\n",
    "        # actual drawing\n",
    "        img_matches = cv2.drawMatches(\n",
    "            img_ref, kp_ref,\n",
    "            img_curr, kp_curr,\n",
    "            good_matches, None,\n",
    "            flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "        )\n",
    "\n",
    "        return img_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d63ce466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 matches\n",
      "Enough matches found\n"
     ]
    }
   ],
   "source": [
    "img_ref = cv2.imread(PATH_TO_IMG1)\n",
    "img_curr = cv2.imread(PATH_TO_IMG2)\n",
    "\n",
    "finder = ORBCorrespondence(\n",
    "    min_matches=3,\n",
    "    check_orientation=False,\n",
    "    window_size=4000\n",
    ")\n",
    "\n",
    "matches_12, matched_pts, num_matches = finder.search_for_initialization(\n",
    "    img_ref, img_curr\n",
    ")\n",
    "\n",
    "print(f\"Found {num_matches} matches\")\n",
    "\n",
    "if num_matches > finder.min_matches:\n",
    "    print(\"Enough matches found\")\n",
    "\n",
    "    # orb features\n",
    "    kp_ref, _ = finder.extract_orb_features(img_ref)\n",
    "    kp_curr, _ = finder.extract_orb_features(img_curr)\n",
    "\n",
    "    # matched coords (to be used in the rest of testing)\n",
    "    pts_ref, pts_curr = finder.get_matched_keypoints(kp_ref, kp_curr, matches_12)\n",
    "\n",
    "    img_matches = finder.visualize_matches(\n",
    "        img_ref, img_curr, \n",
    "        kp_ref, kp_curr, \n",
    "        matches_12\n",
    "    )\n",
    "    cv2.imshow(\"Initial correspondences\", img_matches)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(f\"Not enough matches ({num_matches}/{finder.min_matches})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8532276",
   "metadata": {},
   "source": [
    "## 2. Parallel computation of the two models\n",
    "The two models chosen is the computation of a homography $H_{cr}$ and a fundamental matrix $F_{cr}$. This is done using the normalized DLT and 8-point algorithms respectively, both within a RANSAC scheme. \n",
    "\n",
    "fjasdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08021529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizePts(pts):\n",
    "    \"\"\"\n",
    "    Normalizes the points and returns the transformation matrix as well. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pts: 2D numpy.array (dtype=float)\n",
    "        Coordinates of N points in the left and right view stored in arrays of shape (2,N)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pts_normalized: 2D numpy.array (dtype=float)\n",
    "        Normalized coordinates for the points, centered at the origin w/ mean squared dist = 2 (px)\n",
    "    T: 2D numpy.array (dtype=float)\n",
    "        Transformation matrix for the point (to be undone later in 8pt alg).\n",
    "    \"\"\"\n",
    "    _, n = pts.shape\n",
    "\n",
    "    # Compute the centroid\n",
    "    centroid = np.mean(pts, axis=1)\n",
    "\n",
    "    # Shift to origin\n",
    "    pts_centered = pts - centroid[:, np.newaxis]\n",
    "\n",
    "    # Compute avg dist from origin\n",
    "    scale = np.mean(np.linalg.norm(pts_centered, axis=0)) / np.sqrt(2) # 2 px\n",
    "\n",
    "    # Create T\n",
    "    T = np.linalg.inv(np.array([\n",
    "        [scale, 0, centroid[0]], \n",
    "        [0, scale, centroid[1]], \n",
    "        [0, 0, 1]]))\n",
    "    \n",
    "    # Apply T\n",
    "    pts_normalized = np.dot(T, np.vstack((pts, np.ones(n))))\n",
    "\n",
    "    return pts_normalized, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFitError(pts2L, pts2R, F):\n",
    "    \"\"\"\n",
    "    Computes the quality of the fit measured as the average of (x^T*F*x')^2 over all corresponding points x,x'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pts2L : 2D numpy.array (dtype=float)\n",
    "    pts2R : 2D numpy.array (dtype=float)\n",
    "        Coordinates of N points in the left and right view stored in arrays of shape (2,N)\n",
    "\n",
    "    F : 2D numpy.array (dtype=float)\n",
    "        Fundamental matrix of shape (3,3)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fiterror : float\n",
    "        The quality of the fit measured as the average of (x^T*F*x')^2 over all corresponding points x,x'\n",
    "    \"\"\"\n",
    "    _, n = pts2L.shape\n",
    "    fiterror = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        x = np.array([ # conver to homogeneous corods\n",
    "            pts2L[0, i], pts2L[1, i], 1 \n",
    "        ])\n",
    "        x_ = np.array([\n",
    "            pts2R[0, i], pts2R[1, i], 1\n",
    "        ])\n",
    "\n",
    "        fiterror += (x.T @ F @ x_) ** 2\n",
    "\n",
    "    return fiterror / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d9be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitFudamental(pts2L,pts2R):\n",
    "    \"\"\"\n",
    "    Estimate fundamental matrix from point correspondences in two views \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pts2L : 2D numpy.array (dtype=float)\n",
    "    pts2R : 2D numpy.array (dtype=float)\n",
    "        Coordinates of N points in the left and right view stored in arrays of shape (2,N)\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    F : 2D numpy.array (dtype=float)\n",
    "        Fundamental matrix of shape (3,3)\n",
    "        \n",
    "    fiterror : float\n",
    "        The quality of the fit measured as the average of (x^T*F*x')^2 over all corresponding points x,x'\n",
    "    \n",
    "    \"\"\"    \n",
    "    _, n = pts2L.shape\n",
    "    # needs at least 8 pts\n",
    "    assert(n >= 8)\n",
    "\n",
    "    ### NORMALIZE DATA\n",
    "    # Center data at origin, scale it\n",
    "    # keep transformations for last part\n",
    "    norm_pts2L, T_L = normalizePts(pts2L)\n",
    "    norm_pts2R, T_R = normalizePts(pts2R)\n",
    "\n",
    "    ### EIGHT-POINT ALGORITHM\n",
    "    # for every pair of points (u, v, 1) and (u', v', 1)...\n",
    "    #   add a row add flattened outer product\n",
    "    #   = (uu', uv', u, vu', vv', v, u', v', 1)\n",
    "    #   then use the trick learned from normal E\n",
    "    #   where we only take the last vector of Vt to solve\n",
    "    A = np.array([\n",
    "        [\n",
    "            p1[0] * p2[0], p1[0] * p2[1], p1[0],    # uu', uv', u\n",
    "            p1[1] * p2[0], p1[1] * p2[1], p1[1],    # vu', vv', v\n",
    "            p2[0], p2[1], 1                         # u', v', 1\n",
    "        ] for p1, p2 in zip(norm_pts2L.T, norm_pts2R.T)\n",
    "    ])\n",
    "    _, _, Vt = np.linalg.svd(A)\n",
    "    F = Vt[-1].reshape(3, 3)\n",
    "\n",
    "\n",
    "    ### ENFORCE RANK-2 CONSTRAINT\n",
    "    # Just take svd and throw out smallest singular value\n",
    "    U, S, Vt = np.linalg.svd(F)\n",
    "    S[2] = 0     # remember singular values are sorted\n",
    "    F = U @ np.diag(S) @ Vt\n",
    "\n",
    "    ### TRANSFORM F BACK TO ORIGNAL UNITS\n",
    "    # If T and T' are normalizing transformations, then fix by\n",
    "    # T.T @ F @ T'\n",
    "    F = T_R.T @ F @ T_L\n",
    "    \n",
    "    # print(F)\n",
    "    ### COMPUTE FIT ERROR\n",
    "    fiterror = computeFitError(pts2L, pts2R, F)\n",
    "    \n",
    "    return (F, fiterror)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitFundamentalRANSAC(\n",
    "        pts2L, pts2R, \n",
    "        thresh, \n",
    "        niter=256\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Robust estimation of fundamental matrix from point correspondences in two views \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pts2L : 2D numpy.array (dtype=float)\n",
    "    pts2R : 2D numpy.array (dtype=float)\n",
    "            Coordinates of N points in the left and right view stored in arrays of shape (2,N)\n",
    "\n",
    "    thresh : float\n",
    "        Error threshold to decide whether a point is an inlier or outlier\n",
    "\n",
    "    niter : int\n",
    "        Number of RANSAC iterations to run\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    F : 2D numpy.array (dtype=float)\n",
    "        Fundamental matrix of shape (3,3)\n",
    "    \n",
    "    inliers : numpy.array (dtype=int)\n",
    "        Indices of the points which were determined to be inliers\n",
    "        \n",
    "    fiterror : float\n",
    "        The quality of the fit measured as the average of (x^T*F*x')^2 over all corresponding points x,x'\n",
    "    \n",
    "    \"\"\"    \n",
    "    _, n = pts2L.shape\n",
    "    assert(n >= 8)\n",
    "\n",
    "    # store best inliers\n",
    "    F = np.zeros((3, 3))\n",
    "    inliers = np.array([])\n",
    "    fiterror = float('inf')\n",
    "    \n",
    "\n",
    "    for _ in range(niter):\n",
    "        # Find subset of points\n",
    "        #   choose random subset of MINIMUM points (in this case, 8)\n",
    "        idxs_min = np.random.choice(n, 8, replace=False)\n",
    "\n",
    "        # generate F from sample\n",
    "        F_est, _ = fitFudamental(pts2L[:, idxs_min], pts2R[:, idxs_min])\n",
    "\n",
    "        # compute inliers \n",
    "        inliers_new = []\n",
    "        for i in range(n):\n",
    "            x = np.array([pts2L[0, i], pts2L[1, i], 1])\n",
    "            x_ = np.array([pts2R[0, i], pts2R[1, i], 1])\n",
    "            if abs(x.T @ F_est @ x_) < thresh:\n",
    "                inliers_new.append(i)\n",
    "\n",
    "        # if too few inliers, exit\n",
    "        if len(inliers_new) < 8:\n",
    "            continue\n",
    "        \n",
    "        # generate F with final inliers + score model\n",
    "        F_new, fiterror_new = fitFudamental(pts2L[:, inliers_new], pts2R[:, inliers_new])\n",
    "\n",
    "        # update final F + inliers (if better)\n",
    "        if fiterror_new < fiterror:\n",
    "            F = F_new\n",
    "            inliers = inliers_new\n",
    "            fiterror = fiterror_new\n",
    "    \n",
    "    return (F, inliers, fiterror)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77aa68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitHomography(pts2L, pts2R):\n",
    "    \"\"\"\n",
    "    Estimates a homography between 2 points using (normalized) DLT\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _, n = pts2L.shape\n",
    "    # need at least 4 pts\n",
    "    assert(n >= 4)\n",
    "\n",
    "    ### NORMALIZE DATA\n",
    "    # Center data at origin, scale it\n",
    "    # keep transformations for last part\n",
    "    norm_pts2L, T_L = normalizePts(pts2L)\n",
    "    norm_pts2R, T_R = normalizePts(pts2R)\n",
    "\n",
    "    ### DLT ALGORITHM\n",
    "    #   for every pair of points add 2 new rows\n",
    "    #   [ 0, 0, 0, -pt, pt[1] * pt]\n",
    "    #   [ -pt, [0, 0, 0], -pt[0] * pt]\n",
    "    A = []\n",
    "    for p1, p2 in zip(norm_pts2L.T, norm_pts2R.T):\n",
    "        pass\n",
    "\n",
    "    A = np.array(A)\n",
    "    _, _, Vt = np.linalg.svd(A)\n",
    "    H = Vt[-1].reshape(3, 3)\n",
    "\n",
    "    ### TRANSFORM H BACK TO ORIGNAL UNITS\n",
    "    # If T and T' are normalizing transformations, then fix by\n",
    "    # T.T @ H @ T'\n",
    "    H = T_R.T @ H @ T_L\n",
    "\n",
    "    ### COMPUTE ERROR\n",
    "    pass\n",
    "\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf003f7",
   "metadata": {},
   "source": [
    "The third step is to select a good model. Ideally one that the fundamental matrix has a good result on and the homography on a subset is ideal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d6799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4087173",
   "metadata": {},
   "source": [
    "The fourth step is to perform motion and structure from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
